{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQS_AND_ANNOTATIONS_CHUNKS_DIR = '/cs/phd/nadavb/cafa_project/data/seqs_and_annotations'\n",
    "\n",
    "N_SPECIAL_TOKENS = 2\n",
    "PAD_TOKEN = 0\n",
    "MASK_TOKEN = 1\n",
    "\n",
    "PROT_LETTERS = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "MAX_SEQ_LEN = 1000\n",
    "N_ANNOTATIONS = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set relevant annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10019    14077131\n",
       "4205      4645778\n",
       "2706      3605141\n",
       "4396      2874126\n",
       "24685     2413000\n",
       "           ...   \n",
       "44088           1\n",
       "1871            1\n",
       "11143           1\n",
       "43873           1\n",
       "11461           1\n",
       "Name: count, Length: 26032, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotation_counts = pd.read_csv('/cs/phd/nadavb/cafa_project/data/unique_annotations_counts.csv', \\\n",
    "        index_col = 0, squeeze = True, names = ['count'])\n",
    "display(annotation_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rarest used annotation appears 477 times.\n"
     ]
    }
   ],
   "source": [
    "assert len(annotation_counts) >= N_ANNOTATIONS\n",
    "used_annotation_counts = annotation_counts.iloc[:N_ANNOTATIONS]\n",
    "print('The rarest used annotation appears %d times.' % used_annotation_counts.min())\n",
    "\n",
    "unique_annotations = list(used_annotation_counts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_to_token = {aa: i + N_SPECIAL_TOKENS for i, aa in enumerate(PROT_LETTERS)}\n",
    "annotation_to_index = {annotation: i for i, annotation in enumerate(unique_annotations)}\n",
    "unique_annotations_set = set(unique_annotations)\n",
    "\n",
    "def encode_seqs(batch_seqs, max_len = MAX_SEQ_LEN):\n",
    "    \n",
    "    encoded_seqs = np.full((len(batch_seqs), max_len), PAD_TOKEN, dtype = np.int8)\n",
    "    \n",
    "    for i, seq in enumerate(batch_seqs):\n",
    "        assert len(seq) <= max_len\n",
    "        encoded_seqs[i, :len(seq)] = [aa_to_token[aa] for aa in seq]\n",
    "    \n",
    "    return encoded_seqs\n",
    "\n",
    "def encode_annotations(batch_annotations):\n",
    "    \n",
    "    encoded_annotations = np.zeros((len(batch_annotations), len(unique_annotations)), dtype = np.int8)\n",
    "    \n",
    "    for i, annotations in enumerate(encoded_annotations):\n",
    "        for annotation in annotations:\n",
    "            if annotation in annotation_to_index:\n",
    "                encoded_annotations[i, annotation_to_index[annotation]] = 1\n",
    "                \n",
    "    return encoded_annotations\n",
    "\n",
    "def generate_batches(batch_size = 32, min_encoded_annotations_per_seq = 2, max_consecutive_samples_per_file = 10000):\n",
    "    \n",
    "    chunk_file_names = os.listdir(SEQS_AND_ANNOTATIONS_CHUNKS_DIR)\n",
    "    current_chunk = None\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        print('Starting an iteration on the entire dataset.')\n",
    "        random.shuffle(chunk_file_names)\n",
    "        \n",
    "        for chunk_file_name in chunk_file_names:\n",
    "            \n",
    "            print('Loading %s.' % chunk_file_name)\n",
    "            new_chunk = pd.read_csv(os.path.join(SEQS_AND_ANNOTATIONS_CHUNKS_DIR, chunk_file_name))\n",
    "            new_chunk['complete_go_annotation_indices'] = new_chunk['complete_go_annotation_indices'].apply(json.loads)\n",
    "            \n",
    "            seq_len_mask = (new_chunk['seq'].str.len() <= MAX_SEQ_LEN)\n",
    "            print('Filtering out %d of %d sequences, due to too long (>%d) length.' % ((~seq_len_mask).sum(), \\\n",
    "                    len(new_chunk), MAX_SEQ_LEN))\n",
    "            new_chunk = new_chunk[seq_len_mask]\n",
    "            \n",
    "            sufficient_annotations_mask = new_chunk['complete_go_annotation_indices'].apply(lambda annotations: \\\n",
    "                    len(set(annotations) & unique_annotations_set) >= min_encoded_annotations_per_seq)\n",
    "            print('Filtering out %d of %d sequences, due to insufficient (at least %d) encoded annotations.' % \\\n",
    "                    ((~sufficient_annotations_mask).sum(), len(new_chunk), min_encoded_annotations_per_seq))\n",
    "            new_chunk = new_chunk[sufficient_annotations_mask]\n",
    "            \n",
    "            sample_size = min(max_consecutive_samples_per_file, len(new_chunk))\n",
    "            print('Sampling %d of %d sequences.' % (sample_size, len(new_chunk)))\n",
    "            new_chunk = new_chunk.sample(sample_size)\n",
    "            \n",
    "            if current_chunk is None:\n",
    "                current_chunk = new_chunk\n",
    "            else:\n",
    "                current_chunk = pd.concat([current_chunk, new_chunk]) \n",
    "                \n",
    "            while len(current_chunk) >= batch_size:\n",
    "                \n",
    "                batch_data = current_chunk.iloc[:batch_size]\n",
    "                current_chunk = current_chunk.iloc[batch_size:]\n",
    "                \n",
    "                batch_encoded_seqs = encode_seqs(batch_data['seq'])\n",
    "                batch_encoded_annotations = encode_annotations(batch_data['complete_go_annotation_indices'])\n",
    "                \n",
    "                yield batch_encoded_seqs, batch_encoded_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode target seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxa_id</th>\n",
       "      <th>cafa_id</th>\n",
       "      <th>uniprot_name</th>\n",
       "      <th>seq</th>\n",
       "      <th>complete_go_annotation_indices</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49385</th>\n",
       "      <td>10090</td>\n",
       "      <td>T100900015051</td>\n",
       "      <td>TITIN_MOUSE</td>\n",
       "      <td>MTTQAPMFTQPLQSVVVLEGSTATFEAHVSGSPVPEVSWFRDGQVI...</td>\n",
       "      <td>[]</td>\n",
       "      <td>35213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31041</th>\n",
       "      <td>9606</td>\n",
       "      <td>T96060017620</td>\n",
       "      <td>TITIN_HUMAN</td>\n",
       "      <td>MTTQAPTFTQPLQSVVVLEGSTATFEAHISGFPVPEVSWFRDGQVI...</td>\n",
       "      <td>[]</td>\n",
       "      <td>34350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97089</th>\n",
       "      <td>6239</td>\n",
       "      <td>T62390003241</td>\n",
       "      <td>TTN1_CAEEL</td>\n",
       "      <td>MEGNEKKGGGLPPTQQRHLNIDTTVGGSISQPVSPSMSYSTDRETV...</td>\n",
       "      <td>[135, 2818, 3561, 4178, 4205, 6231, 10256, 106...</td>\n",
       "      <td>18562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86722</th>\n",
       "      <td>7227</td>\n",
       "      <td>T72270003175</td>\n",
       "      <td>TITIN_DROME</td>\n",
       "      <td>MQRQNPNPYQQQNQQHQQVQQFSSQEYSHSSQEQHQEQRISRTEQH...</td>\n",
       "      <td>[]</td>\n",
       "      <td>18141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24127</th>\n",
       "      <td>9606</td>\n",
       "      <td>T96060010706</td>\n",
       "      <td>MUC16_HUMAN</td>\n",
       "      <td>MLKPSGLPGSSSPTRSLMTGSRSTKATPEMDSGLTGATLSPKTSTG...</td>\n",
       "      <td>[1541, 1542, 1545, 1573, 1696, 1749, 2001, 200...</td>\n",
       "      <td>14507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>4577</td>\n",
       "      <td>T45770000753</td>\n",
       "      <td>UC22_MAIZE</td>\n",
       "      <td>IFFEV</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30735</th>\n",
       "      <td>9606</td>\n",
       "      <td>T96060017314</td>\n",
       "      <td>TDB01_HUMAN</td>\n",
       "      <td>GTGG</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31923</th>\n",
       "      <td>9606</td>\n",
       "      <td>T96060018502</td>\n",
       "      <td>TUFT_HUMAN</td>\n",
       "      <td>TKPR</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57851</th>\n",
       "      <td>9823</td>\n",
       "      <td>T98230001354</td>\n",
       "      <td>TRH_PIG</td>\n",
       "      <td>QHP</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31600</th>\n",
       "      <td>9606</td>\n",
       "      <td>T96060018179</td>\n",
       "      <td>TRDD1_HUMAN</td>\n",
       "      <td>EI</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       taxa_id        cafa_id uniprot_name  \\\n",
       "49385    10090  T100900015051  TITIN_MOUSE   \n",
       "31041     9606   T96060017620  TITIN_HUMAN   \n",
       "97089     6239   T62390003241   TTN1_CAEEL   \n",
       "86722     7227   T72270003175  TITIN_DROME   \n",
       "24127     9606   T96060010706  MUC16_HUMAN   \n",
       "...        ...            ...          ...   \n",
       "752       4577   T45770000753   UC22_MAIZE   \n",
       "30735     9606   T96060017314  TDB01_HUMAN   \n",
       "31923     9606   T96060018502   TUFT_HUMAN   \n",
       "57851     9823   T98230001354      TRH_PIG   \n",
       "31600     9606   T96060018179  TRDD1_HUMAN   \n",
       "\n",
       "                                                     seq  \\\n",
       "49385  MTTQAPMFTQPLQSVVVLEGSTATFEAHVSGSPVPEVSWFRDGQVI...   \n",
       "31041  MTTQAPTFTQPLQSVVVLEGSTATFEAHISGFPVPEVSWFRDGQVI...   \n",
       "97089  MEGNEKKGGGLPPTQQRHLNIDTTVGGSISQPVSPSMSYSTDRETV...   \n",
       "86722  MQRQNPNPYQQQNQQHQQVQQFSSQEYSHSSQEQHQEQRISRTEQH...   \n",
       "24127  MLKPSGLPGSSSPTRSLMTGSRSTKATPEMDSGLTGATLSPKTSTG...   \n",
       "...                                                  ...   \n",
       "752                                                IFFEV   \n",
       "30735                                               GTGG   \n",
       "31923                                               TKPR   \n",
       "57851                                                QHP   \n",
       "31600                                                 EI   \n",
       "\n",
       "                          complete_go_annotation_indices  seq_len  \n",
       "49385                                                 []    35213  \n",
       "31041                                                 []    34350  \n",
       "97089  [135, 2818, 3561, 4178, 4205, 6231, 10256, 106...    18562  \n",
       "86722                                                 []    18141  \n",
       "24127  [1541, 1542, 1545, 1573, 1696, 1749, 2001, 200...    14507  \n",
       "...                                                  ...      ...  \n",
       "752                                                   []        5  \n",
       "30735                                                 []        4  \n",
       "31923                                                 []        4  \n",
       "57851                                                 []        3  \n",
       "31600                                                 []        2  \n",
       "\n",
       "[97999 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SEQS_CSV_FILE_PATH = '/cs/phd/nadavb/cafa_project/data/target_seqs_expanded_annotations.csv.gz'\n",
    "\n",
    "def generate_target_seqs_batches(batch_size = 32, min_max_len = 1000):\n",
    "    \n",
    "    target_seqs = pd.read_csv(TARGET_SEQS_CSV_FILE_PATH)\n",
    "    target_seqs['seq_len'] = target_seqs['seq'].str.len()\n",
    "    target_seqs.sort_values('seq_len', inplace = True, ascending = False)\n",
    "    \n",
    "    while len(target_seqs) > 0:\n",
    "        \n",
    "        batch_seqs = target_seqs.iloc[:batch_size]\n",
    "        target_seqs = target_seqs.iloc[batch_size:]\n",
    "    \n",
    "        batch_encoded_seqs = encode_seqs(batch_seqs['seq'], max_len = max(min_max_len, batch_seqs['seq_len'].max()))\n",
    "        batch_encoded_annotations = encode_annotations(batch_seqs['complete_go_annotation_indices'])\n",
    "\n",
    "        yield batch_seqs.index.values, batch_seqs['cafa_id'].values, batch_encoded_seqs, batch_encoded_annotations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
