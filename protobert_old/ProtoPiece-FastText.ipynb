{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "\n",
    "\n",
    "* note: for sent2vec - an improvement - \"A SIMPLE BUT TOUGH TO BEAT BASELINE FOR SENTENCE EMBEDDINGS\"\n",
    "     * https://github.com/peter3125/sentence2vec/blob/master/sentence2vec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gzip\n",
    "\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "\n",
    "import fasttext\n",
    "\n",
    "# https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "# model = KeyedVectors.load_word2vec_format('../input/en.wiki.bpe.op1000.d25.w2v.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_FASTA_RECORDS = False\n",
    "TRAIN_SENTENCE_PIECE = False\n",
    "EXTRACT_H5 = False\n",
    "\n",
    "EXTRACT_SENTPIECE_TOKENIZED_SEQ = False\n",
    "\n",
    "TRAIN_FAST_TEXT_UNSUPERVISED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_SENTPIECE_LABELED_TOKENIZED_SEQ = True\n",
    "LABELED_DATA_FILE_PATH = \"labelled_toy_seqs_v1.csv.gz\"\n",
    "\n",
    "TRAIN_LABELED_DATA_FILE_PATH = \"labelled_toy_seqs_v1_TRAIN.csv\"\n",
    "TEST_LABELED_DATA_FILE_PATH = \"labelled_toy_seqs_v1_TEST.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "# # os.chdir(os.path.normpath(r\"C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\"))\n",
    "# os.chdir(r\"C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\")\n",
    "print(os.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a plain text with protein seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> wget ftp://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd \"C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\\data\")\n",
    "print(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_FASTA_FILE_PATH = '/cs/phd/nadavb/cafa_project/data/uniref90.fasta.gz'\n",
    "# CORPUS_TXT_FILE_PATH = '/cs/phd/nadavb/cafa_project/data/seqs_for_sentencepeice_training.txt'\n",
    "\n",
    "# INPUT_FASTA_FILE_PATH =os.path.normpath('./data/uniclust30_2016_150K_sampledSeq.fasta.gz')\n",
    "INPUT_FASTA_FILE_PATH =os.path.normpath(r'C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\\data\\uniref_90_go-manual+OR+manual-annotation_transmem+OR+annotation_signal.fasta.gz')\n",
    "\n",
    "# INPUT_FASTA_FILE_PATH =os.path.normpath(r'C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\\data\\uniclust30_2016_150K_sampledSeq.fasta.gz')\n",
    "CORPUS_TXT_FILE_PATH = os.path.normpath(r'seqs_for_sentencepeice_training.txt')\n",
    "\n",
    "\n",
    "#### TODO: Add more output files names here - e.g. for training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instead of taking just the first sequences, it could be better to take a random subsample. \n",
    "if EXTRACT_FASTA_RECORDS:\n",
    "    \n",
    "    N_SEQS = 3123456\n",
    "\n",
    "    with gzip.open(INPUT_FASTA_FILE_PATH, 'rt') as input_fasta_file, open(CORPUS_TXT_FILE_PATH, 'w') as output_txt_file:\n",
    "        for i, record in enumerate(SeqIO.parse(input_fasta_file, 'fasta')):\n",
    "\n",
    "            if N_SEQS is not None and i >= N_SEQS:\n",
    "                break\n",
    "\n",
    "            if i % 5000 == 0:\n",
    "                print(i, end = '\\r')\n",
    "\n",
    "            output_txt_file.write(str(record.seq) + '\\n')\n",
    "\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentencepiece model\n",
    "* Note: we will want a larger vocab size here than with our language model. W2V will embed it anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # %cd /cs/phd/nadavb/cafa_project/data\n",
    "# !cd \"C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\\data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 150000\n",
    "# VOCAB_SIZE = 120\n",
    "N_RESERVED_SYMBOLS = 2 # We want to reserve two symbols: 1) for PADDING, 2) for MASKING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_SENTENCE_PIECE:\n",
    "\n",
    "    # spm.SentencePieceTrainer.Train('--input=%s --model_prefix=protopiece --vocab_size=%d' % (CORPUS_TXT_FILE_PATH, \\\n",
    "    #         VOCAB_SIZE - N_RESERVED_SYMBOLS))\n",
    "\n",
    "\n",
    "    # spm.SentencePieceTrainer.Train('--input=uniclust30_2016_150K_sampledSeq.txt --model_prefix=protopiece --vocab_size=%d' % (VOCAB_SIZE - N_RESERVED_SYMBOLS))\n",
    "\n",
    "    spm.SentencePieceTrainer.Train('--input=seqs_for_sentencepeice_training.txt --model_prefix=protopiece --vocab_size=%d' % (VOCAB_SIZE - N_RESERVED_SYMBOLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('protopiece.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‚ñÅMR', 'YTV', 'LI', 'ALQGA', 'LLLLLL', 'IDD', 'GQGQ', 'SPY', 'PYPGM', 'PCNS', 'SRQ', 'CGLG', 'TCV', 'HSR', 'CAHC', 'SSDGT', 'LCSP', 'EDPT', 'MVW', 'PCC', 'PESS', 'CQL', 'VVGLP', 'SLVN', 'HYN', 'CLPN', 'QCTD', 'SSQ', 'CPGG', 'FGC', 'MTRR', 'SKC', 'ELCK', 'ADGE', 'ACN', 'SPYL', 'DWR', 'KDKE', 'CCSG', 'YCH', 'TEA', 'RGLE', 'GVCI', 'DPKK', 'IFCT', 'PKNP', 'WQLA', 'PY', 'PPSY', 'HQPT', 'TLR', 'PPTS', 'LYD', 'SWL', 'MSGF', 'LVKS', 'TTAPS', 'TQEE', 'EDDY']\n",
      "[655, 3305, 47, 141230, 24038, 2016, 36487, 3745, 94062, 91117, 3179, 41419, 4092, 4405, 58966, 133981, 68152, 61759, 13002, 11200, 11596, 6963, 106956, 11777, 7427, 60750, 120571, 1136, 41053, 5389, 88397, 4962, 26075, 11347, 7615, 45153, 6476, 11195, 91448, 18012, 1208, 21204, 56175, 12521, 61546, 30860, 64125, 335, 19965, 75693, 1013, 9918, 2639, 4151, 43987, 25858, 117697, 20654, 39569]\n"
     ]
    }
   ],
   "source": [
    "example_seq = 'MRYTVLIALQGALLLLLLIDDGQGQSPYPYPGMPCNSSRQCGLGTCVHSRCAHCSSDGTLCSPEDPTMVWPCCPESSCQLVVG' + \\\n",
    "              'LPSLVNHYNCLPNQCTDSSQCPGGFGCMTRRSKCELCKADGEACNSPYLDWRKDKECCSGYCHTEARGLEGVCIDPKKIFCTP' + \\\n",
    "              'KNPWQLAPYPPSYHQPTTLRPPTSLYDSWLMSGFLVKSTTAPSTQEEEDDY'\n",
    "\n",
    "print(sp.encode_as_pieces(example_seq))\n",
    "print(sp.encode_as_ids(example_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess our dataset sequences using the trained sentencepiece model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_H5_FILE_PATH = '/cs/phd/nadavb/cafa_project/data/protein_tokens.h5'\n",
    "\n",
    "DATASET_H5_FILE_PATH = os.path.normpath(r'C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\\data\\protein_tokens.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_FASTA_FILE_PATH = os.path.normpath(r'C:\\Users\\Dan Ofer\\Desktop\\Stuff\\cafa\\ProteinBert\\data\\uniclust30_2016_150K_sampledSeq.txt')\n",
    "\n",
    "# INPUT_FASTA_FILE_PATH = os.path.normpath(r\".\\data\\uniclust30_2016_150K_sampledSeq.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SEQS = 1000000\n",
    "\n",
    "if EXTRACT_H5:\n",
    "    REP_ID_PATTERN = re.compile(r'RepID=(\\S+)')\n",
    "\n",
    "    with gzip.open(INPUT_FASTA_FILE_PATH, 'rt') as input_fasta_file, h5py.File(DATASET_H5_FILE_PATH, 'w') as h5f:\n",
    "\n",
    "        h5f_group = h5f.create_group('protein_tokens')\n",
    "        h5f_rep_id = h5f_group.create_dataset('rep_id', shape = (N_SEQS,), dtype = h5py.string_dtype())\n",
    "        h5f_tokens = h5f_group.create_dataset('tokens', shape = (N_SEQS,), dtype = h5py.vlen_dtype(np.int16))\n",
    "        h5f_seq_length = h5f_group.create_dataset('seq_length', shape = (N_SEQS,), dtype = np.int32)\n",
    "        h5f_n_tokens = h5f_group.create_dataset('n_tokens', shape = (N_SEQS,), dtype = np.int32)\n",
    "\n",
    "        for i, record in enumerate(SeqIO.parse(input_fasta_file, 'fasta')):\n",
    "\n",
    "            if N_SEQS is not None and i >= N_SEQS:\n",
    "                break\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(i, end = '\\r')\n",
    "\n",
    "            rep_id, = REP_ID_PATTERN.findall(record.description)\n",
    "            tokens = sp.encode_as_ids(str(record.seq))\n",
    "            seq_length = len(record.seq)\n",
    "            n_tokens = len(tokens)\n",
    "\n",
    "            h5f_rep_id[i] = rep_id\n",
    "            h5f_tokens[i] = tokens\n",
    "            h5f_seq_length[i] = seq_length\n",
    "            h5f_n_tokens[i] = n_tokens\n",
    "\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_H5:\n",
    "    with h5py.File(DATASET_H5_FILE_PATH, 'r') as h5f:\n",
    "        h5f_group = h5f['protein_tokens']\n",
    "        all_n_tokens = h5f_group['n_tokens'][:]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10, 4))\n",
    "    ax.hist(all_n_tokens, bins = 200)\n",
    "    ax.set_xlabel('# Tokens')\n",
    "    ax.set_ylabel('# Seqs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fasttext\n",
    "\n",
    "* First we tokenize using sentencepiece\n",
    "    * optionally save output to file, if not already saved\n",
    "* tran fasttext/word2vec model on text. (unsupervised).\n",
    "* +- train supervised model vs compare to k-nn retrieval model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sentence piece model tokenization of a given file\n",
    "* Expect a file with 1 protein sequence per row, no headers or fasta descriptors\n",
    "* saves tokenized output (in text format) to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_SENTPIECE_TOKENIZED_SEQ: \n",
    "    text = pd.read_csv(CORPUS_TXT_FILE_PATH,header=None,names=[\"seq\"],\n",
    "    #                    nrows=140\n",
    "                      )\n",
    "    print(text.shape)\n",
    "    ## orig - .apply(\", \".join)\n",
    "    text[\"seq\"] = text[\"seq\"].apply(sp.encode_as_pieces).apply(\" \".join) # apply to get rid of brackets around tokenized text\n",
    "    display(text.head())\n",
    "\n",
    "    text[\"seq\"].to_csv(\"tokenized_sp_fasta.csv\",index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train fasttext or word2vec model on tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "# fasttext.train_supervised\n",
    "# fasttext.train_unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext params\n",
    "\n",
    "    input             # training file path (required)\n",
    "    model             # unsupervised fasttext model {cbow, skipgram} [skipgram]\n",
    "    lr                # learning rate [0.05]\n",
    "    dim               # size of word vectors [100]\n",
    "    ws                # size of the context window [5]\n",
    "    epoch             # number of epochs [5]\n",
    "    minCount          # minimal number of word occurences [5]\n",
    "    minn              # min length of char ngram [3]\n",
    "    maxn              # max length of char ngram [6]\n",
    "    neg               # number of negatives sampled [5]\n",
    "    wordNgrams        # max length of word ngram [1]\n",
    "    loss              # loss function {ns, hs, softmax, ova} [ns]\n",
    "    bucket            # number of buckets [2000000]\n",
    "    thread            # number of threads [number of cpus]\n",
    "    lrUpdateRate      # change the rate of updates for the learning rate [100]\n",
    "    t                 # sampling threshold [0.0001]\n",
    "    verbose           # verbose [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: hyperparameter search on these variables\n",
    "EMBEDDING_DIM = 150\n",
    "WINDOW_SIZE = 5\n",
    "FT_MODEL = \"skipgram\" #'cbow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained, saving\n",
      "model_file_150D_5ws_skipgram.bin\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_FAST_TEXT_UNSUPERVISED:\n",
    "    model = fasttext.train_unsupervised(\"tokenized_sp_fasta.csv\", \n",
    "    #                                     model=FT_MODEL,\n",
    "#                                         lr=0.05,\n",
    "                                        dim=EMBEDDING_DIM,\n",
    "                                        ws=WINDOW_SIZE,\n",
    "#                                         epoch=2,\n",
    "                                        thread=3,  # -1 for all\n",
    "                                        minn=1,maxn=2,\n",
    "                                        minCount=4,\n",
    "                                        verbose=1\n",
    "#                                        neg=6\n",
    "                                       )\n",
    "    print(\"model trained, saving\")\n",
    "    print(f\"model_file_{EMBEDDING_DIM}D_{WINDOW_SIZE}ws_{FT_MODEL}.bin\")\n",
    "#     model.save_model(\"model_file.bin\")\n",
    "\n",
    "    model.save_model(f\"model_file_{EMBEDDING_DIM}D_{WINDOW_SIZE}ws_{FT_MODEL}.bin\") ## useful if testing hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train supervised model\n",
    "## OPT: purely retrieval based/knn model\n",
    "\n",
    "* Using toy data, precleaned - first column is sequencer, next columns are labels\n",
    "    * note - supervised fasttext treats multilabel as multiclass! \n",
    "    \n",
    "* Toy data downloaded from drive : labelled_toy_seqs_v1.csv.gz   , https://drive.google.com/open?id=1mHdkZFv_gNvgWdpzMqKMLCgMOPb84fDU\n",
    "\n",
    "\n",
    "* as another strong classification/embedding baseline - can use the \"sentence2vec\" file code - from https://github.com/peter3125/sentence2vec/blob/master/sentence2vec.py \n",
    "    * A SIMPLE BUT TOUGH TO BEAT BASELINE FOR SENTENCE EMBEDDINGS\n",
    "    \n",
    "    \n",
    "* may want to try `scikit-multilearn` package - http://scikit.ml/stratification.html\n",
    "    * I use this to get stratified train/test split, across the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40407, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Cell membrane</th>\n",
       "      <th>Disulfide bond</th>\n",
       "      <th>Endoplasmic reticulum</th>\n",
       "      <th>Glycoprotein</th>\n",
       "      <th>Hydrolase</th>\n",
       "      <th>Ion transport</th>\n",
       "      <th>Membrane</th>\n",
       "      <th>Metal-binding</th>\n",
       "      <th>Phosphoprotein</th>\n",
       "      <th>Receptor</th>\n",
       "      <th>Repeat</th>\n",
       "      <th>Secreted</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Transferase</th>\n",
       "      <th>Transmembrane</th>\n",
       "      <th>Transport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGLSYGLFICFLLWAGTGLCYPPTTTEDKTHPSLPSSPSVVVECRH...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MACRQRGGSWSPSGWFNAGWSTYRSISLFFALVTSGNSIDVSQLVN...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAGFRSLLVLLLVFPSGCVGFRSPLSVFKRFKETTRSFSNECLGTT...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MELRPWLLWVVAATGTLVLLAADAQGQKVFTNTWAVRIPGGPAVAN...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MELRPWLLWVVAAAGALVLLAAEARGQKIFTNTWAVHISGGPAVAD...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sequence Cell membrane  \\\n",
       "0  MGLSYGLFICFLLWAGTGLCYPPTTTEDKTHPSLPSSPSVVVECRH...             1   \n",
       "1  MACRQRGGSWSPSGWFNAGWSTYRSISLFFALVTSGNSIDVSQLVN...             1   \n",
       "2  MAGFRSLLVLLLVFPSGCVGFRSPLSVFKRFKETTRSFSNECLGTT...             0   \n",
       "3  MELRPWLLWVVAATGTLVLLAADAQGQKVFTNTWAVRIPGGPAVAN...             1   \n",
       "4  MELRPWLLWVVAAAGALVLLAAEARGQKIFTNTWAVHISGGPAVAD...             1   \n",
       "\n",
       "  Disulfide bond Endoplasmic reticulum Glycoprotein Hydrolase Ion transport  \\\n",
       "0              1                     0            1         0             0   \n",
       "1              1                     0            1         0             0   \n",
       "2              1                     0            1         0             0   \n",
       "3              1                     0            1         1             0   \n",
       "4              1                     0            1         1             0   \n",
       "\n",
       "  Membrane Metal-binding Phosphoprotein Receptor Repeat Secreted Signal  \\\n",
       "0        1             0              0        1      0        1      1   \n",
       "1        1             0              0        1      0        1      1   \n",
       "2        1             1              1        0      1        0      1   \n",
       "3        1             1              1        0      1        1      1   \n",
       "4        1             1              1        0      1        1      1   \n",
       "\n",
       "  Transferase Transmembrane Transport  \n",
       "0           0             1         0  \n",
       "1           0             1         0  \n",
       "2           0             1         0  \n",
       "3           0             1         0  \n",
       "4           0             1         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ### stratified sampling of dataset into set train/test splits for comparison\n",
    "# # !pip install scikit-multilearn\n",
    "\n",
    "# print(LABELED_DATA_FILE_PATH)\n",
    "# df = pd.read_csv(LABELED_DATA_FILE_PATH)#.sample(n=2134)#.iloc[:,0:5]\n",
    "# column_names = df.columns\n",
    "# print(df.shape)\n",
    "\n",
    "# ## stratified multilabel sampling - http://scikit.ml/stratification.html\n",
    "# from skmultilearn.model_selection import iterative_train_test_split\n",
    "# X_train,y_train, X_test, y_test = iterative_train_test_split(X=df.values, y=df.drop([\"Sequence\"],axis=1).values, test_size = 0.25)\n",
    "\n",
    "# df_train = pd.DataFrame(X_train,columns=column_names)\n",
    "# df_test = pd.DataFrame(X_test,columns=column_names)\n",
    "\n",
    "# display(df_train.head())\n",
    "\n",
    "# df_train.to_csv(\"labelled_toy_seqs_v1_TRAIN.csv\",index=False)\n",
    "# df_test.to_csv(\"labelled_toy_seqs_v1_TEST.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv(\"labelled_toy_seqs_v1_TRAIN.csv\",index=False)\n",
    "# df_test.to_csv(\"labelled_toy_seqs_v1_TEST.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Sentence piece tokenizer to train/test data and save tokenized modified version\n",
    "* TODO:  should save different data processing outputs in different folders..  (raw, input, tokenized, modified..)\n",
    "\n",
    "* sentence piece model used for tokenizing must match , otherwise our embeddings will be bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_SENTPIECE_LABELED_TOKENIZED_SEQ: \n",
    "    # train\n",
    "    text = pd.read_csv(TRAIN_LABELED_DATA_FILE_PATH)\n",
    "    text[\"Sequence\"] = text[\"Sequence\"].apply(sp.encode_as_pieces).apply(\" \".join)\n",
    "    text.to_csv(\"tokenized_\"+TRAIN_LABELED_DATA_FILE_PATH,index=False,encoding=\"utf-8\")\n",
    "    # test file\n",
    "    text = pd.read_csv(TEST_LABELED_DATA_FILE_PATH)\n",
    "    text[\"Sequence\"] = text[\"Sequence\"].apply(sp.encode_as_pieces).apply(\" \".join)\n",
    "    text.to_csv(\"tokenized_\"+TEST_LABELED_DATA_FILE_PATH,index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Cell membrane</th>\n",
       "      <th>Disulfide bond</th>\n",
       "      <th>Endoplasmic reticulum</th>\n",
       "      <th>Glycoprotein</th>\n",
       "      <th>Hydrolase</th>\n",
       "      <th>Ion transport</th>\n",
       "      <th>Membrane</th>\n",
       "      <th>Metal-binding</th>\n",
       "      <th>Phosphoprotein</th>\n",
       "      <th>Receptor</th>\n",
       "      <th>Repeat</th>\n",
       "      <th>Secreted</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Transferase</th>\n",
       "      <th>Transmembrane</th>\n",
       "      <th>Transport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ñÅMASS YFLF LCLLL CGG PELC NSQT LWLL PGGT PTPV ...</td>\n",
       "      <td>__label__Cell membrane</td>\n",
       "      <td>__label__Disulfide bond</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Glycoprotein</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Receptor</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Secreted</td>\n",
       "      <td>__label__Signal</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Transmembrane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚ñÅMQ GGRVV LGLLC CLV AGV GSYT PWD ISW AARG DPSA...</td>\n",
       "      <td>__label__Cell membrane</td>\n",
       "      <td>__label__Disulfide bond</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Glycoprotein</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Secreted</td>\n",
       "      <td>__label__Signal</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Transmembrane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‚ñÅMA GGSA TTW GYPV ALLLL VATLG LGRW LQPD PGLPG ...</td>\n",
       "      <td>__label__Cell membrane</td>\n",
       "      <td>__label__Disulfide bond</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Glycoprotein</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Secreted</td>\n",
       "      <td>__label__Signal</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Transmembrane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‚ñÅMD WLFF RN ICLLI IL MVVM EVNSE FIV EVKE FDIE ...</td>\n",
       "      <td>__label__Cell membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Glycoprotein</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Membrane</td>\n",
       "      <td>__label__Metal-binding</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Repeat</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Signal</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Transmembrane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‚ñÅMH CLVI LGFLL GSLVA FSW AGVT TQPP PLI RTLS AG...</td>\n",
       "      <td>__label__Cell membrane</td>\n",
       "      <td>__label__Disulfide bond</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Glycoprotein</td>\n",
       "      <td>__label__Hydrolase</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Membrane</td>\n",
       "      <td>__label__Metal-binding</td>\n",
       "      <td>__label__Phosphoprotein</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Signal</td>\n",
       "      <td>0</td>\n",
       "      <td>__label__Transmembrane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sequence           Cell membrane  \\\n",
       "0  ‚ñÅMASS YFLF LCLLL CGG PELC NSQT LWLL PGGT PTPV ...  __label__Cell membrane   \n",
       "1  ‚ñÅMQ GGRVV LGLLC CLV AGV GSYT PWD ISW AARG DPSA...  __label__Cell membrane   \n",
       "2  ‚ñÅMA GGSA TTW GYPV ALLLL VATLG LGRW LQPD PGLPG ...  __label__Cell membrane   \n",
       "3  ‚ñÅMD WLFF RN ICLLI IL MVVM EVNSE FIV EVKE FDIE ...  __label__Cell membrane   \n",
       "4  ‚ñÅMH CLVI LGFLL GSLVA FSW AGVT TQPP PLI RTLS AG...  __label__Cell membrane   \n",
       "\n",
       "            Disulfide bond  Endoplasmic reticulum           Glycoprotein  \\\n",
       "0  __label__Disulfide bond                      0  __label__Glycoprotein   \n",
       "1  __label__Disulfide bond                      0  __label__Glycoprotein   \n",
       "2  __label__Disulfide bond                      0  __label__Glycoprotein   \n",
       "3                        0                      0  __label__Glycoprotein   \n",
       "4  __label__Disulfide bond                      0  __label__Glycoprotein   \n",
       "\n",
       "            Hydrolase  Ion transport           Membrane  \\\n",
       "0                   0              0  __label__Membrane   \n",
       "1                   0              0  __label__Membrane   \n",
       "2                   0              0  __label__Membrane   \n",
       "3                   0              0  __label__Membrane   \n",
       "4  __label__Hydrolase              0  __label__Membrane   \n",
       "\n",
       "            Metal-binding           Phosphoprotein           Receptor  \\\n",
       "0                       0                        0  __label__Receptor   \n",
       "1                       0                        0                  0   \n",
       "2                       0                        0                  0   \n",
       "3  __label__Metal-binding                        0                  0   \n",
       "4  __label__Metal-binding  __label__Phosphoprotein                  0   \n",
       "\n",
       "            Repeat           Secreted           Signal  Transferase  \\\n",
       "0                0  __label__Secreted  __label__Signal            0   \n",
       "1                0  __label__Secreted  __label__Signal            0   \n",
       "2                0  __label__Secreted  __label__Signal            0   \n",
       "3  __label__Repeat                  0  __label__Signal            0   \n",
       "4                0                  0  __label__Signal            0   \n",
       "\n",
       "            Transmembrane  Transport  \n",
       "0  __label__Transmembrane          0  \n",
       "1  __label__Transmembrane          0  \n",
       "2  __label__Transmembrane          0  \n",
       "3  __label__Transmembrane          0  \n",
       "4  __label__Transmembrane          0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.head().loc[:, :].replace(1, \"__label__\"+pd.Series(text.columns, text.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised FastText model\n",
    "* can use gensim instead\n",
    "* Fasttext expect speicifc format\n",
    "* doesn't really do multilabel\n",
    "\n",
    "*FT expects All the labels to start with the `__label__` prefix, which is how fastText recognize what is a label or what is a word.  `__label__`.\n",
    "    * code : https://stackoverflow.com/questions/37032043/how-to-replace-a-value-in-a-pandas-dataframe-with-column-name-based-on-a-conditi   + add `__label__` prefix , `text.head().loc[:, :].replace(1, \"__label__\"+pd.Series(text.columns, text.columns))`\n",
    "    \n",
    "    * might need to remove spaces from targets/column names to avoid leaks?? \n",
    "    * also remove 0s otherwise can be a leak as well \n",
    "    * write out as space delimited text file siomply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_raw = pd.read_csv(TRAIN_LABELED_DATA_FILE_PATH)\n",
    "# print(\"train shape\",df_train_raw.shape)\n",
    "# df_test_raw = pd.read_csv(TEST_LABELED_DATA_FILE_PATH)\n",
    "# print(\"test shape\",df_test_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* make version of text data for fasttext , with suffixes on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv(\"tokenized_\"+TRAIN_LABELED_DATA_FILE_PATH)\n",
    "\n",
    "#### remove whitespace from columns/labels \n",
    "text.columns = text.columns.str.replace(\" \",\"-\")\n",
    "text.loc[:, :].replace(1, \"__label__\"+pd.Series(text.columns, text.columns),inplace=True)\n",
    "text.replace(0,np.nan,inplace=True)\n",
    "\n",
    "text.to_csv(\"fastText_train.txt\",sep=' ', index=False, header=False,quoting=None)\n",
    "\n",
    "## same for test\n",
    "\n",
    "\n",
    "text = pd.read_csv(\"tokenized_\"+TEST_LABELED_DATA_FILE_PATH)\n",
    "\n",
    "#### remove whitespace from columns/labels \n",
    "text.columns = text.columns.str.replace(\" \",\"-\")\n",
    "text.loc[:, :].replace(1, \"__label__\"+pd.Series(text.columns, text.columns),inplace=True)\n",
    "text.replace(0,np.nan,inplace=True)\n",
    "\n",
    "text.to_csv(\"fastText_test.txt\",sep=' ', index=False, header=False,quoting=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train supervised fasttext model\n",
    "* output of \"predict\" is samples, precision , recall\n",
    "    * precision can be changed to get Prec/recall at @ top k \n",
    "    \n",
    "* the threshholdd/probabiltiies doesn't seem to work in python+Windows?? \n",
    "    * same for autotune of hyperparams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://fasttext.cc/docs/en/supervised-tutorial.html#multi-label-classification\n",
    "\n",
    "model = fasttext.train_supervised(input=\"fastText_train.txt\", loss='ova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__Membrane', '__label__Transmembrane', '__label__Glycoprotein', '__label__Signal', '__label__Disulfide-bond', '__label__Cell-membrane', '__label__Transport', '__label__Secreted', '__label__Phosphoprotein', '__label__Repeat', '__label__Metal-binding', '__label__Receptor', '__label__Hydrolase', '__label__Endoplasmic-reticulum', '__label__Transferase', '__label__Ion-transport']\n"
     ]
    }
   ],
   "source": [
    "# print(model.words)\n",
    "print(model.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's have a look on our predictions, we want as many prediction as possible (argument -1) and we want only labels with probability higher or equal to 0.5 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test() got an unexpected keyword argument 'threshold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-a1d914ae2e96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fastText_test.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: test() got an unexpected keyword argument 'threshold'"
     ]
    }
   ],
   "source": [
    "model.test(\"fastText_test.txt\", k=-1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t10071\n",
      "P@1\t0.762\n",
      "R@1\t0.503\n"
     ]
    }
   ],
   "source": [
    "print_results(*model.test('fastText_test.txt', k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
